{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5ddpjcALLiI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "storage_path = \"gs://fynd-open-source/research/MILDNet\"\n",
    "os.environ[\"STORAGE_PATH\"]=storage_path\n",
    "config = 'mildnet.cnf'\n",
    "os.environ[\"MILDNET_CONFIG\"] = \"job_configs/{}\".format(config)\n",
    "\n",
    "%cd /content\n",
    "!rm -rf /content/mildnet\n",
    "!git clone https://github.com/samehraban/mildnet\n",
    "\n",
    "%cd mildnet\n",
    "\n",
    "MILDNET_JOB_DIR='output'\n",
    "MILDNET_REGION=\"\"\n",
    "MILDNET_DATA_PATH=storage_path\n",
    "HYPERDASH_KEY=''\n",
    "\n",
    "with open(\"settings.cfg\", \"w\") as f:\n",
    "  f.write(\"MILDNET_JOB_DIR={}\\nMILDNET_REGION={}\\nMILDNET_DATA_PATH={}\\nHYPERDASH_KEY={}\"\n",
    "          .format(MILDNET_JOB_DIR, MILDNET_REGION, MILDNET_DATA_PATH, HYPERDASH_KEY))\n",
    "\n",
    "if not os.path.exists(\"dataset\"):\n",
    "  !mkdir dataset\n",
    "!gsutil cp $STORAGE_PATH/tops.zip dataset/tops.zip\n",
    "!unzip -q dataset/tops.zip -d dataset/\n",
    "\n",
    "!gsutil cp $STORAGE_PATH/tops_val_full.csv .\n",
    "\n",
    "with open(\"tops_val_full.csv\", \"r\") as file:\n",
    "  db = file.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XiJPn-K2om_n"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements-local-gpu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_dir = 'output'\n",
    "data_path = 'gs://fynd-open-source/research/MILDNet'\n",
    "model_id=\"Mildnet_vgg16\"\n",
    "loss=\"contrastive_loss\"\n",
    "optimizer=\"mo\"\n",
    "weights_path = None\n",
    "train_csv=\"tops_train_shuffle.csv\"\n",
    "val_csv=\"tops_val_full.csv\"\n",
    "train_epocs=30\n",
    "batch_size=16\n",
    "lr=0.001\n",
    "hyperdash_key = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "colab_type": "code",
    "id": "hLuJCZiXSob-",
    "outputId": "21947196-9ce4-4b74-8b21-5ec527bea4b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_configs/Mildnet.cnf\n",
      "INFO:root:Downloading Training Image from path gs://ml_shared_bucket/MildNet/\n",
      "INFO:root:Building Model: Mildnet_vgg16\n",
      "2019-03-07 07:12:44.184180: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-03-07 07:12:44.255522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-03-07 07:12:44.256021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 11.17GiB freeMemory: 9.99GiB\n",
      "2019-03-07 07:12:44.256060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n",
      "2019-03-07 07:12:44.599244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-03-07 07:12:44.599326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n",
      "2019-03-07 07:12:44.599362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n",
      "2019-03-07 07:12:44.599672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9678 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "INFO:root:Total params: 21,927,744\n",
      "INFO:root:Trainable params: 20,192,256\n",
      "INFO:root:Non-trainable params: 1,735,488\n",
      "INFO:root:Found 70748 images belonging to 3 classes. Query Images: 1604, Positive Image: 4063, Negative Images: 64627\n",
      "INFO:root:Found 24163 images belonging to 3 classes. Query Images: 604, Positive Image: 1293, Negative Images: 23452\n",
      "Epoch 1/30\n",
      "  20/4419 [..............................] - ETA: 1:50:24 - loss: 0.4634 - accuracy: 51.2500"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "needs_reproducible = True\n",
    "if needs_reproducible:\n",
    "    from numpy.random import seed\n",
    "\n",
    "    seed(1)\n",
    "    from tensorflow import set_random_seed\n",
    "\n",
    "    set_random_seed(2)\n",
    "\n",
    "from trainer.checkpointers import *\n",
    "from trainer.accuracy import *\n",
    "from trainer.utils import *\n",
    "from trainer.model import *\n",
    "import inspect\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import dill\n",
    "from hyperdash import Experiment\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "\n",
    "batch_size *= 3\n",
    "is_full_data = False\n",
    "hyperdash_capture_io = True\n",
    "\n",
    "# Setting up Hyperdash\n",
    "def get_api_key():\n",
    "    return hyperdash_key\n",
    "\n",
    "if hyperdash_key:\n",
    "    exp = Experiment(model_id, get_api_key, capture_io=hyperdash_capture_io)\n",
    "    exp.param(\"model_name\", job_dir.split(\"/\")[-1])\n",
    "    exp.param(\"data_path\", data_path)\n",
    "    exp.param(\"batch_size\", batch_size)\n",
    "    exp.param(\"train_epocs\", train_epocs)\n",
    "    exp.param(\"optimizer\", optimizer)\n",
    "    exp.param(\"lr\", lr)\n",
    "    if weights_path:\n",
    "        exp.param(\"weights_path\", weights_path)\n",
    "    exp.param(\"loss\", loss)\n",
    "    exp.param(\"train_csv\", train_csv)\n",
    "    exp.param(\"val_csv\", val_csv)\n",
    "\n",
    "logging.info(\"Downloading Training Image from path {}\".format(data_path))\n",
    "downloads_training_images(data_path, is_cropped=(\"_cropped\" in job_dir))\n",
    "\n",
    "logging.info(\"Building Model: {}\".format(model_id))\n",
    "if model_id in globals():\n",
    "    model_getter = globals()[model_id]\n",
    "    model = model_getter()\n",
    "else:\n",
    "    raise RuntimeError(\"Failed. Model function {} not found\".format(model_id))\n",
    "\n",
    "if loss + \"_fn\" in globals():\n",
    "    _loss_tensor = globals()[loss + \"_fn\"](batch_size)\n",
    "else:\n",
    "    raise RuntimeError(\"Failed. Loss function {} not found\".format(loss + \"_fn\"))\n",
    "\n",
    "accuracy = accuracy_fn(batch_size)\n",
    "img_width, img_height = [int(v) for v in model.input[0].shape[1:3]]\n",
    "\n",
    "trainable_count, non_trainable_count = print_trainable_counts(model)\n",
    "\n",
    "if hyperdash_key:\n",
    "    exp.param(\"trainable_count\", trainable_count)\n",
    "    exp.param(\"non_trainable_count\", non_trainable_count)\n",
    "\n",
    "print('***********')\n",
    "print('data_path: ' + data_path)\n",
    "print('train_csv: ', train_csv)\n",
    "print('valid_csv: ', val_csv)\n",
    "print('***********')\n",
    "\n",
    "dg = DataGenerator({\n",
    "    \"rescale\": 1. / 255,\n",
    "    \"horizontal_flip\": True,\n",
    "    \"vertical_flip\": True,\n",
    "    \"zoom_range\": 0.2,\n",
    "    \"shear_range\": 0.2,\n",
    "    \"rotation_range\": 30\n",
    "}, data_path, train_csv, val_csv, target_size=(img_width, img_height))\n",
    "\n",
    "train_generator = dg.get_train_generator(batch_size, is_full_data)\n",
    "test_generator = dg.get_test_generator(batch_size)\n",
    "\n",
    "if weights_path:\n",
    "    with file_io.FileIO(weights_path, mode='r') as input_f:\n",
    "        with file_io.FileIO(\"weights.h5\", mode='w+') as output_f:\n",
    "            output_f.write(input_f.read())\n",
    "    model.load_weights(\"weights.h5\")\n",
    "\n",
    "# model = multi_gpu_model(model, gpus=4)\n",
    "if optimizer == \"mo\":\n",
    "    model.compile(loss=_loss_tensor,\n",
    "                  optimizer=tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.9, use_nesterov=True),\n",
    "                  metrics=[accuracy])\n",
    "elif optimizer == \"rms\":\n",
    "    model.compile(loss=_loss_tensor, optimizer=tf.train.RMSPropOptimizer(lr), metrics=[accuracy])\n",
    "else:\n",
    "    logging.error(\"Optimizer not supported\")\n",
    "    raise ValuError\n",
    "\n",
    "csv_logger = CSVLogger(job_dir, \"output/training.log\")\n",
    "model_checkpoint_path = \"weights-improvement-{epoch:02d}-{val_loss:.2f}.h5\"\n",
    "model_checkpointer = ModelCheckpoint(job_dir, model_checkpoint_path, save_best_only=True, save_weights_only=True,\n",
    "                                     monitor=\"val_loss\", verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=job_dir + '/logs/', histogram_freq=0, write_graph=True, write_images=True)\n",
    "# test_accuracy = TestAccuracy(data_path)  # Not using test data as of now\n",
    "\n",
    "callbacks = [csv_logger, model_checkpointer, tensorboard]\n",
    "if hyperdash_key:\n",
    "    callbacks.append(HyperdashCallback(exp))\n",
    "\n",
    "model_json = model.to_json()\n",
    "write_file_and_backup(model_json, job_dir, \"output/model.def\")\n",
    "\n",
    "with open(\"output/model_code.pkl\", 'wb') as f:\n",
    "    dill.dump(model_getter, f)\n",
    "backup_file(job_dir, \"output/model_code.pkl\")\n",
    "\n",
    "model_code = inspect.getsource(model_getter)\n",
    "write_file_and_backup(model_code, job_dir, \"output/model_code.txt\")\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=(train_generator.n // (train_generator.batch_size)),\n",
    "                              validation_data=test_generator,\n",
    "                              epochs=train_epocs,\n",
    "                              validation_steps=(test_generator.n // (test_generator.batch_size)),\n",
    "                              callbacks=callbacks)\n",
    "\n",
    "backup_file(job_dir, \"output/history.csv\")\n",
    "\n",
    "model.save_weights('output/model.h5')\n",
    "backup_file(job_dir, 'output/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qciROc52xE_D"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SVzDmGVpxItD"
   },
   "source": [
    "The code published the results at gcloud storage path set on the global config param MildNET_JOB_DIR. Besides this all the output can also be found in the \"output\" folder.\n",
    "- Training logs are stored in \"training.log file\"\n",
    "- Model details are stored in \"model.def\", \"model_code.pkl\", \"model_code.txt\" files\n",
    "- Model weights where improvements in validation accuracy is observed is stored in format weights-improvement-{{epoch_number}}-{{validation_loss}}.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nvNApG9XzfWm"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "zo-kndRqzhaz",
    "outputId": "8bb3944e-11be-4fd8-cb4e-668249aa9d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from model.def file\n",
      "\n",
      "Loading weights from top performing epoch: output/weights-improvement-01-0.40.h5\n",
      "\n",
      "The model accepts input of size: [224,224,3]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "print(\"Loading model from model.def file\\n\")\n",
    "json_file = open(\"output/model.def\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "weights = glob.glob(\"output/weights-improvement-*\")\n",
    "weights.sort()\n",
    "print(\"Loading weights from top performing epoch: {}\\n\".format(weights[-1]))\n",
    "model.load_weights(weights[-1])\n",
    "\n",
    "img_size = int(model.input.shape[1])\n",
    "print(\"The model accepts input of size: [{},{},3]\".format(img_size, img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "bFAtpG-E0Gq1",
    "outputId": "68b886a6-7bf0-45b3-a6fc-49a85b3c725f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance b/w query and positive image: 0.203023552895\n",
      "Distance b/w query and negative image: 0.217806831002\n",
      "\n",
      "Model performed correctly\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "def preprocess_img(image):\n",
    "  p_image = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), (img_size, img_size))\n",
    "  p_image = np.expand_dims(p_image, axis=0)\n",
    "  return p_image\n",
    "\n",
    "def get_pred(model, image):\n",
    "  if model.input_shape[0]:\n",
    "    op_quer = model.predict([image,image,image])\n",
    "  else:\n",
    "    op_quer = model.predict(image)\n",
    "  return op_quer\n",
    "\n",
    "def load_image_and_preprocess(image):\n",
    "  image = cv2.imread('dataset/tops/{}'.format(image))\n",
    "  image = preprocess_img(image)\n",
    "  return image\n",
    "\n",
    "def test_triplet(model):\n",
    "  with open(\"tops_val_full.csv\", \"r\") as file:\n",
    "    triplets = file.read().split(\"\\n\")\n",
    "    \n",
    "    triplet = triplets[0]\n",
    "    q, p, n = triplet.split(\",\")\n",
    "    \n",
    "    q, p, n = load_image_and_preprocess(q), load_image_and_preprocess(p), load_image_and_preprocess(n)\n",
    "    \n",
    "    batch_x = np.zeros((3, 224, 224, 3), dtype=K.floatx())\n",
    "    batch_x[:] = [q, p, n]\n",
    "    \n",
    "    pred_q, pred_p, pred_n = get_pred(model, batch_x)\n",
    "    \n",
    "    D_q_p = np.sqrt(np.sum(np.square(pred_q - pred_p)))\n",
    "    D_q_n = np.sqrt(np.sum(np.square(pred_q - pred_n)))\n",
    "    \n",
    "    print(\"Distance b/w query and positive image: {}\\nDistance b/w query and negative image: {}\\n\\nModel performed {}\"\n",
    "          .format(D_q_p,D_q_n,\"correctly\" if D_q_p<D_q_n else \"incorrectly\"))\n",
    "    \n",
    "test_triplet(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MildNet on Colab.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
