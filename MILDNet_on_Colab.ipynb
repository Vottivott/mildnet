{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5ddpjcALLiI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "storage_path = \"gs://fynd-open-source/research/MILDNet\"\n",
    "os.environ[\"STORAGE_PATH\"]=storage_path\n",
    "\n",
    "!rm -rf mildnet\n",
    "!git clone https://github.com/gofynd/mildnet\n",
    "\n",
    "%cd mildnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7I_b2sG_6KXL"
   },
   "source": [
    "**Since currently the code only supports Tensorflow 1.10.0 and Cuda version 9.0, we have to change the versions on Colab. This might take a few minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XiJPn-K2om_n"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements-local-gpu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kedFhonUrQtr"
   },
   "outputs": [],
   "source": [
    "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
    "!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
    "!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n",
    "!apt-get update\n",
    "!apt-get install cuda=9.0.176-1\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "vVrZ1B9f5xvY",
    "outputId": "75e9a96d-1da2-4baa-abae-bd016ff4fbb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://fynd-open-source/research/MILDNet/tops.zip...\n",
      "| [1 files][658.5 MiB/658.5 MiB]                                                \n",
      "Operation completed over 1 objects/658.5 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists(\"dataset\"):\n",
    "  !mkdir dataset\n",
    "!gsutil cp $STORAGE_PATH/tops.zip dataset/tops.zip\n",
    "!unzip -q dataset/tops.zip -d dataset/\n",
    "\n",
    "!gsutil cp $STORAGE_PATH/tops_val_full.csv .\n",
    "\n",
    "with open(\"tops_val_full.csv\", \"r\") as file:\n",
    "  db = file.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kou8KAs47cxl"
   },
   "source": [
    "#Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "BkGWaiTDrLyk"
   },
   "outputs": [],
   "source": [
    "#@title Set Global Configs:  { run: \"auto\" }\n",
    "#@markdown MILDNET_JOB_DIR (**mandatory**): Requires directory path to store training outputs. Either pass path of local directory or Google cloud storage (gs://.....)\n",
    "\n",
    "MILDNET_JOB_DIR='output' #@param {type:\"string\"}\n",
    "MILDNET_REGION=\"\"\n",
    "MILDNET_DATA_PATH=storage_path\n",
    "#@markdown HYPERDASH_KEY (**optional**): Hyperdash key for live logging to mobile device.\n",
    "HYPERDASH_KEY='' #@param {type:\"string\"}\n",
    "\n",
    "with open(\"settings.cfg\", \"w\") as f:\n",
    "  f.write(\"MILDNET_JOB_DIR={}\\nMILDNET_REGION={}\\nMILDNET_DATA_PATH={}\\nHYPERDASH_KEY={}\"\n",
    "          .format(MILDNET_JOB_DIR, MILDNET_REGION, MILDNET_DATA_PATH, HYPERDASH_KEY))\n",
    "\n",
    "# print(\"Kindly tally the configs:\")\n",
    "# !cat settings.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "id": "m9vY7q22inK6",
    "outputId": "0b9a757e-2402-4f0a-b271-f03193e66ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Default Models: \u001b[0m\n",
      "    1: alexnet.cnf\n",
      "    2: ranknet.cnf\n",
      "    3: vanila_vgg16.cnf\n",
      "    4: visnet.cnf\n",
      "    5: mildnet.cnf\n",
      "    6: visnet-lrn2d.cnf\n",
      "\u001b[1m Mildnet Ablation Study \u001b[0m\n",
      "    1: mildnet_skip_3.cnf\n",
      "    2: mildnet_skip_2.cnf\n",
      "    3: mildnet_skip_4.cnf\n",
      "    4: mildnet_skip_1.cnf\n",
      "\u001b[1m Mildnet Low Features \u001b[0m\n",
      "    1: mildnet_512_512.cnf\n",
      "    2: mildnet_1024_512.cnf\n",
      "    3: mildnet_512_no_dropout.cnf\n",
      "\u001b[1m Mildnet Other Losses \u001b[0m\n",
      "    1: mildnet_hinge_new.cnf\n",
      "    2: mildnet_angular_2.cnf\n",
      "    3: mildnet_contrastive.cnf\n",
      "    4: mildnet_lossless.cnf\n",
      "    5: mildnet_angular_1.cnf\n",
      "\u001b[1m Mildnet Other Variants \u001b[0m\n",
      "    1: mildnet_without_skip_big.cnf\n",
      "    2: mildnet_vgg19.cnf\n",
      "    3: mildnet_vgg16_big.cnf\n",
      "    4: mildnet_without_skip.cnf\n",
      "    5: mildnet_mobilenet.cnf\n",
      "    6: mildnet_all_trainable.cnf\n",
      "    7: mildnet_cropped.cnf\n"
     ]
    }
   ],
   "source": [
    "#@title Available Configs:\n",
    "import glob\n",
    "\n",
    "def bold_text(text):\n",
    "  return \"\\033[1m {} \\033[0m\".format(text)\n",
    "\n",
    "configs = {\"Default Models:\": glob.glob(\"job_configs/*.cnf\")}\n",
    "for path in glob.glob(\"job_configs/*/*.cnf\"):\n",
    "  conf_type = path.split(\"/\")[-2].replace(\"_\",\" \").title()\n",
    "  if conf_type in configs:\n",
    "      configs[conf_type].append(path)\n",
    "  else:\n",
    "      configs[conf_type] = [path]\n",
    "\n",
    "confs = {}\n",
    "conf_types = list(configs.keys())\n",
    "conf_types.sort()\n",
    "for conf_type in conf_types:\n",
    "  print(bold_text(conf_type))\n",
    "  counter = 0\n",
    "  for path in configs[conf_type]:\n",
    "    counter+=1\n",
    "    confs[str(len(confs)+1)] = path\n",
    "    print(\"    {}: {}\".format(counter, path.split(\"/\")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "bhCjdQ7l0ATE"
   },
   "outputs": [],
   "source": [
    "#@title Select a Config: { run: \"auto\" }\n",
    "config = 'mildnet.cnf' #@param ['mildnet.cnf','ranknet.cnf','visnet.cnf','vanila_vgg16.cnf','visnet-lrn2d.cnf','alexnet.cnf','mildnet_ablation_study/mildnet_skip_1.cnf','mildnet_ablation_study/mildnet_skip_2.cnf','mildnet_ablation_study/mildnet_skip_3.cnf','mildnet_ablation_study/mildnet_skip_4.cnf','mildnet_low_features/mildnet_1024_512.cnf','mildnet_low_features/mildnet_512_512.cnf','mildnet_low_features/mildnet_512_no_dropout.cnf','mildnet_other_losses/mildnet_angular_1.cnf','mildnet_other_losses/mildnet_angular_2.cnf','mildnet_other_losses/mildnet_contrastive.cnf','mildnet_other_losses/mildnet_hinge_new.cnf','mildnet_other_losses/mildnet_lossless.cnf','mildnet_other_variants/mildnet_all_trainable.cnf','mildnet_other_variants/mildnet_cropped.cnf','mildnet_other_variants/mildnet_mobilenet.cnf','mildnet_other_variants/mildnet_vgg16_big.cnf','mildnet_other_variants/mildnet_vgg19.cnf','mildnet_other_variants/mildnet_without_skip.cnf','mildnet_other_variants/mildnet_without_skip_big.cnf']\n",
    "import os\n",
    "os.environ[\"MILDNET_CONFIG\"] = \"job_configs/{}\".format(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL4C0nnXw_xu"
   },
   "source": [
    "#Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "colab_type": "code",
    "id": "hLuJCZiXSob-",
    "outputId": "21947196-9ce4-4b74-8b21-5ec527bea4b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_configs/mildnet.cnf\n",
      "INFO:root:Downloading Training Image from path gs://ml_shared_bucket/MILDNet/\n",
      "INFO:root:Building Model: mildnet_vgg16\n",
      "2019-03-07 07:12:44.184180: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-03-07 07:12:44.255522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-03-07 07:12:44.256021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 11.17GiB freeMemory: 9.99GiB\n",
      "2019-03-07 07:12:44.256060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n",
      "2019-03-07 07:12:44.599244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-03-07 07:12:44.599326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n",
      "2019-03-07 07:12:44.599362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n",
      "2019-03-07 07:12:44.599672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9678 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "INFO:root:Total params: 21,927,744\n",
      "INFO:root:Trainable params: 20,192,256\n",
      "INFO:root:Non-trainable params: 1,735,488\n",
      "INFO:root:Found 70748 images belonging to 3 classes. Query Images: 1604, Positive Image: 4063, Negative Images: 64627\n",
      "INFO:root:Found 24163 images belonging to 3 classes. Query Images: 604, Positive Image: 1293, Negative Images: 23452\n",
      "Epoch 1/30\n",
      "  20/4419 [..............................] - ETA: 1:50:24 - loss: 0.4634 - accuracy: 51.2500"
     ]
    }
   ],
   "source": [
    "!bash gcloud.local.run.keras.sh $MILDNET_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qciROc52xE_D"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SVzDmGVpxItD"
   },
   "source": [
    "The code published the results at gcloud storage path set on the global config param MILDNET_JOB_DIR. Besides this all the output can also be found in the \"output\" folder.\n",
    "- Training logs are stored in \"training.log file\"\n",
    "- Model details are stored in \"model.def\", \"model_code.pkl\", \"model_code.txt\" files\n",
    "- Model weights where improvements in validation accuracy is observed is stored in format weights-improvement-{{epoch_number}}-{{validation_loss}}.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nvNApG9XzfWm"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "zo-kndRqzhaz",
    "outputId": "8bb3944e-11be-4fd8-cb4e-668249aa9d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from model.def file\n",
      "\n",
      "Loading weights from top performing epoch: output/weights-improvement-01-0.40.h5\n",
      "\n",
      "The model accepts input of size: [224,224,3]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "print(\"Loading model from model.def file\\n\")\n",
    "json_file = open(\"output/model.def\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "weights = glob.glob(\"output/weights-improvement-*\")\n",
    "weights.sort()\n",
    "print(\"Loading weights from top performing epoch: {}\\n\".format(weights[-1]))\n",
    "model.load_weights(weights[-1])\n",
    "\n",
    "img_size = int(model.input.shape[1])\n",
    "print(\"The model accepts input of size: [{},{},3]\".format(img_size, img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "bFAtpG-E0Gq1",
    "outputId": "68b886a6-7bf0-45b3-a6fc-49a85b3c725f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance b/w query and positive image: 0.203023552895\n",
      "Distance b/w query and negative image: 0.217806831002\n",
      "\n",
      "Model performed correctly\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "def preprocess_img(image):\n",
    "  p_image = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), (img_size, img_size))\n",
    "  p_image = np.expand_dims(p_image, axis=0)\n",
    "  return p_image\n",
    "\n",
    "def get_pred(model, image):\n",
    "  if model.input_shape[0]:\n",
    "    op_quer = model.predict([image,image,image])\n",
    "  else:\n",
    "    op_quer = model.predict(image)\n",
    "  return op_quer\n",
    "\n",
    "def load_image_and_preprocess(image):\n",
    "  image = cv2.imread('dataset/tops/{}'.format(image))\n",
    "  image = preprocess_img(image)\n",
    "  return image\n",
    "\n",
    "def test_triplet(model):\n",
    "  with open(\"tops_val_full.csv\", \"r\") as file:\n",
    "    triplets = file.read().split(\"\\n\")\n",
    "    \n",
    "    triplet = triplets[0]\n",
    "    q, p, n = triplet.split(\",\")\n",
    "    \n",
    "    q, p, n = load_image_and_preprocess(q), load_image_and_preprocess(p), load_image_and_preprocess(n)\n",
    "    \n",
    "    batch_x = np.zeros((3, 224, 224, 3), dtype=K.floatx())\n",
    "    batch_x[:] = [q, p, n]\n",
    "    \n",
    "    pred_q, pred_p, pred_n = get_pred(model, batch_x)\n",
    "    \n",
    "    D_q_p = np.sqrt(np.sum(np.square(pred_q - pred_p)))\n",
    "    D_q_n = np.sqrt(np.sum(np.square(pred_q - pred_n)))\n",
    "    \n",
    "    print(\"Distance b/w query and positive image: {}\\nDistance b/w query and negative image: {}\\n\\nModel performed {}\"\n",
    "          .format(D_q_p,D_q_n,\"correctly\" if D_q_p<D_q_n else \"incorrectly\"))\n",
    "    \n",
    "test_triplet(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MILDNet on Colab.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
